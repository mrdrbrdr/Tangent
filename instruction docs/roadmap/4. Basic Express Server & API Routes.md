Below is a **low-level roadmap** for **Step 4: Basic Express Server & API Routes**. In this step, you’ll create your main server file, set up a simple Express app, and define a few basic endpoints. We’ll start with a basic health check route and then add a preliminary chat route that you can later expand to integrate with the LLM and your database.

---

## **4. Basic Express Server & API Routes**

### **4.1 Create Your Main Server File**

1. **File Location** ✔️
	- Create a new file at `src/server/index.js`.

2. **Initialize a Basic Express App**: ✔️
	- In `src/server/index.js`, add the following code:
```
// src/server/index.js
const express = require('express');
const app = express();

// Middleware to parse JSON bodies
app.use(express.json());

// Basic health check route
app.get('/api/health', (req, res) => {
  res.json({ status: 'OK' });
});

// Placeholder chat route for later integration
app.post('/api/chat', async (req, res) => {
  // For now, just echo the user input back as a response
  const userInput = req.body.message;
  // Here, you can later integrate the LLM call and DB logic
  res.json({ response: `You said: ${userInput}` });
});

// Start the server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});
```

2. **Explanation**: ✔️
    - **express.json() Middleware**: This lets the server parse incoming JSON payloads.
    - **GET /api/health**: A simple endpoint to verify your server is running.
    - **POST /api/chat**: A placeholder route that simply echoes back user input. We’ll expand this later.
    - The server listens on port 3000 (or an environment-defined port).


---

### **4.2 Update Your `package.json` Scripts (if needed)** ✔️

- Ensure that your scripts in `package.json` are set up to run your server using nodemon during development. For example:
```
{
  "scripts": {
    "dev": "nodemon src/server/index.js",
    "start": "node src/server/index.js",
    "migrate": "prisma migrate dev"
  }
}
```
- This way, running `npm run dev` will start your server and automatically restart it when files change.

---

### **4.3 Test Your Server**✔️

1. **Start the Server**: ✔️
    - Open your terminal in the project’s root directory and run:
        `npm run dev`
    - You should see a message like `Server running on port 3000`.

2. **Test the Health Check Route**: ✔️
    - Open your browser or a tool like Postman, Insomnia, or even curl.
    - Visit `http://localhost:3000/api/health` to see:
		`{ "status": "OK" }`

3. **Test the Chat Route**: ✔️
    - Use Postman or curl to send a POST request to `http://localhost:3000/api/chat` with a JSON body. For example:
		`{   "message": "Hello, Tangent!" }`
    - You should receive a response like:
		`{ "response": "You said: Hello, Tangent!" }`
		
    **Curl Example**:✔️
		`curl -X POST -H "Content-Type: application/json" -d "{\"message\":\"Hello, Tangent!\"}" http://localhost:3000/api/chat`

---

### **4.4 Commit Your Changes**

1. **Stage and Commit**:
    - After verifying that your routes work as expected, add your changes to Git:
```
git add src/server/index.js package.json
git commit -m "Set up basic Express server and API routes"
```


---

### **4.5 Next Steps**

With your Express server up and running and your basic endpoints working, you’re now ready to move on to integrating the LLM and connecting your database. This will happen in the following steps when we expand the `/api/chat` route to:
- Accept user input.
- Call the OpenAI API for LLM responses.
- Store and retrieve conversation data from the SQLite database via Prisma.